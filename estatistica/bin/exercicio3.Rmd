---
title: "UFPR PPGEcon 2024"
subtitle: "Estatística (Prof. Adalto Acir Althaus Jr.): exercícios"
author: "Alceu Nascimento, João Maurício Rolim e Tiago Soares"
date: "2024-04-21"
output: 
  html_document: 
    toc: TRUE
    toc_float: TRUE
    toc_depth: 5
---

```{r setup, warning=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# definir notação cientifica off em numeros menores que 1.000.000.000.000 ----
# definir qual o tipo do separador (ponto ou virgula) ----
options(scipen = 10, digits = 10, OutDec = ".")
# basic ----
library(writexl)               # Salva as tabelas elaboradas em formato .xls
library(readxl)                # Reads Microsoft Excel spreadsheets.
library(knitr)                 # tabelas kable
library(kableExtra)            # Build common complex HTML tables and manipulate table styles.
library(readr)                 # A fast and friendly way to read tabular data into R.
library(MASS)                  # visualiza decimal em fracoes
library(xtable)                # transforma tabela Excel para Latex
library(ggplot2)               # graficos
library(gridExtra)
# data manipulation ----
library(tidyverse)             # Inclui dplyr, forcats, ggplto2, lubridate, purrr, stringr, tibble, tidyr
library(broom)                 # Converte saídas de modelos estatísticos em tibbles
library(dbplyr)                # Interface dplyr para bancos de dados
library(lubridate)             # Simplifica trabalho com datas e horas
# statistics ----
library(stargazer)             # analise estatistica
library(skimr)                 # Compact and flexible summaries of data, a frictionless, pipeable approach to dealing with summary statistic
library(broom)                 # Convert statistical analysis objects into tidy data frames.
library(lmtest)                # Hypothesis testing for linear regression models.
library(modelsummary)          # faz um grafico de intervalo bom
library(strucchange)           # analisar quebras estruturais (Chow Test)
library(mctest)                # teste para multicolinearidad
library(performance)           # Analisa regressão 
library(broom)                 # takes the messy output of built-in functions in R, such as lm, nls, or t.test, and turns them into tidy tibbles.
library(Plothtests)
library(nortest)               # Anderson-Darling Test for normality
library(Hmisc)
library(pastecs)
library(stats)
```

# Exerício 03

## Questão A

O gerente de controle de qualidade de uma fábrica de lâmpadas precisa
estimar a durabilidade média de uma nova remessa de lâmpadas.
Uma amostra aleatória de 64 lâmpadas foi selecionada nessa remessa e
indicou média de vida útil de 350 horas e desvio-padrão de 100 horas.

\   

### a) Entenda as etapas dos cálculos executadas abaixo.

```{r q1 a, options}
# Parâmetros da amostra
n <- 64  # Tamanho da amostra
x_hat <- 350  # Média amostral
sd <- 100  # Desvio padrão amostral
gamma <- 0.95 # Nivel de confiança
gl <- n - 1  # Graus de liberdade
```

```{r q1 a apuracao}
# apuração
gl <- n -1 
erro_padrao <- sd / sqrt(n)
var <- sd^2
alpha <- (1 - gamma)
t_alpha_meio <- qt( (1 - (alpha/2) ), gl)
m <- t_alpha_meio * erro_padrao
x_hat_menos_m <- x_hat - m 
x_hat_mais_m <-x_hat + m

# tabela
parametros <- c(n, x_hat, sd, gamma)
nomes_parametros <- c("Tamanho da Amostra (n)", "Média Amostral (x_hat)", "Desvio Padrão (sd)", "Nível de Confiança (gamma)")

apuracao <- c(gl, erro_padrao, var, alpha, t_alpha_meio, m, x_hat_menos_m, x_hat_mais_m)
nomes_apuracao <- c("Graus de Liberdade (gl)", "Erro Padrao (erro_padrao)", "Variância amostral (var)", "Nivel de Significancia(alpha)", "Valor crítico de t (t_alpha_meio)", "Margem de Erro (m)", "Limite Inferior do IC (x_hat_menos_m)", "Limite Superior do IC (x_hat_mais_m)")

# Combinando todos os valores e nomes em um dataframe
tabela <- data.frame(
  Variavel = c(nomes_parametros, nomes_apuracao),
  Valor = c(parametros, apuracao)
)

# Mostrando a tabela
print(tabela)
```

```{r q1 base t para graficos, options}
# Criando uma sequência de valores t
t_values <- seq(-4, 4, length.out = 300)
# Criando um data frame para o ggplot
df_t <- data.frame(t = t_values, densidade = dt(t_values, gl))

# Calculando os valores t críticos para o nivel de confiança indicado nos parametros
t_crit_inf <- qt( ((1 - gamma) / 2), gl)  # Valor t para a cauda inferior
t_crit_sup <- qt(gamma + ((1 - gamma) / 2), gl)  # Valor t para a cauda superior

# Gráfico
t_plot <- ggplot(df_t, aes(x = t, y = densidade)) +
  geom_line(color = "black", size = 0.5) +
    labs(title = "Distribuição t") +
  theme_bw()
print(t_plot)
```


```{r q1 a grafico bilateral, options}
# bilateral
print(t_plot + 
        geom_vline(xintercept = t_crit_sup, color = "red", linetype = "dashed", linewidth = 1) +
        geom_vline(xintercept = t_crit_inf, color = "red", linetype = "dashed", linewidth = 1) +
        labs(subtitle = "Teste Bilateral")
      )

```

```{r q1 a graficos genericos unilateral esquerda, options}
# unilateral esquerda
print(t_plot + 
        geom_vline(xintercept = t_crit_inf, color = "red", linetype = "dashed", linewidth = 1) +
        labs(subtitle = "Teste Unilateral à esquerda")
      )
```

```{r q1 a graficos genericos unilateral direita}
# nilateral direita
print(t_plot + 
        geom_vline(xintercept = t_crit_sup, color = "red", linetype = "dashed", linewidth = 1) +
        labs(subtitle = "Teste Unilateral à direita")
      )
```


\  

### b) Modifique a confiança e veja o que acontece com a precisão do intervalo.

```{r q1 b, options}
# Níveis de confiança para avaliar
confiancas <- c(0.90, 0.95, 0.99, 0.995, 0.999, 0.9995)

# Inicializar um data frame para os resultados
resultados <- data.frame(
  Confianca = numeric(),
  LimiteInferior = numeric(),
  LimiteSuperior = numeric()
)

# Cálculo dos intervalos de confiança para cada nível de confiança
for (confianca in confiancas) {
  alpha <- 1 - confianca
  t_alpha_meio <- qt(1 - alpha / 2, gl)
  erro_padrao <- sd / sqrt(n)
  m <- t_alpha_meio * erro_padrao
  limite_inferior <- x_hat - m
  limite_superior <- x_hat + m
  # Adicionar os resultados ao data frame
  resultados <- rbind(resultados, data.frame(Confianca = confianca,
                                             LimiteInferior = limite_inferior,
                                             LimiteSuperior = limite_superior,
                                             Intervalo = m))
}

# Mostrar a tabela
print(resultados)
```

\  

### c) Seria possível aceitar a reivindicação do fornecedor de que as lâmpadas duram 400 horas?

Para determinar se é possível aceitar a reivindicação do fornecedor de
que as lâmpadas duram em média 400 horas, podemos realizar um teste de
hipóteses com as seguintes hipóteses:

$H_0: μ = 400$ (hipótese nula: a média da população é 400 horas)\
$H_a: μ < 400$ (hipótese alternativa: a média da população é menor que 400
horas)

Considerando o nível de confiança de 95% e a média amostral de 350 horas
com desvio padrão de 100 horas para uma amostra de 64 lâmpadas, o teste
de hipóteses (unilateral à esquerda) pode ser conduzido da seguinte maneira:

```{r q1 c, options}
# parametro de teste
mu_0 <- 400

# Cálculo da estatística de teste (t)
t <- (x_hat - mu_0) / erro_padrao

# P-valor para o teste unicaudal à esquerda
p_valor <- pt(t, gl)

# Teste de hipótese
if (p_valor < alpha) {
  resultado <- "Rejeita H_0"
} else {
  resultado <- "Não rejeita H_0"
}

# Resultados
list(t = t, p_valor = p_valor, resultado = resultado)
```

```{r q1 c grafico, options}
# Criar dados para o gráfico
x <- seq(-4, 4, length.out = 300)
df_t <- data.frame(x = x, y = dt(x, gl))

# Adicionar regiões críticas para UNILATERAL A ESQUERDA
critical_left <- qt(alpha, gl, lower.tail = TRUE)

# Gráfico
p <- ggplot(df_t, aes(x = x, y = y)) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = t, color = "blue", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_left, color = "red", linetype = "dashed", linewidth = 1) +
  geom_area(data = df_t %>% filter(x <= critical_left), aes(x = x, y = y), fill = "red", alpha = 0.5) +
    labs(title = "Distribuição t e Estatística de Teste",
       subtitle = paste("Teste de hipótese para média, p-valor:", round(p_valor, 4)),
       x = "Valores t", y = "Densidade") +
  theme_bw()

print(p)
```

\  

## Questão B

### Dados

```{r data, options}
# carregando o dataset
path = "C:/Users/DELL/OneDrive/R/Rprojetos/ufpr_ppgecon/estatistica/data/exerc3_dataset.csv"
dados <- read_csv2(path)
head(dados)
```

### Questão:

A planilha DEMO traz informações de 1.000 respondentes quanto à sua
idade em anos, o seu estado civil (1- casado , 0- não casado), quanto
tempo (em anos) vive no endereço atual, sua renda anual (em milhares de
reais), o preço do carro principal (em milhares de reais), sua
escolaridade (1- primeiro grau, 2- segundo grau, 3- terceiro grau, 4-
Pós graduação especialização, 5- mestrado/doutorado), 
quanto tempo, em anos, está no emprego atual (t_emp_atual), se é (1) ou
não (0) aposentado, o sexo (m- masc e f- femin) e sua satisfação no
trabalho (de 1- Nada satisfeito a 5- Muito satisfeito).

\  

#### Item 1

##### **a) Calcule um intervalo de confiança de $95%$ para a média de idade da população sob amostragem.**
\  
Considerando que é uma amostra aleatória de $n$ observações, com média $\bar{x}$ e desvio padrão $s$, 
proveniente de uma distribuição populacional normalmente distribuída com média $\mu$, podemos utilizar:

$$
t = \frac{\bar{x}- \mu}{ \frac{s}{\sqrt{n}}}
$$
\  
Sendo que a estimatica do intervalo de confiança será:

$$
\bar{x} - t_{n-1,\frac{\alpha}{2}} \frac{s}{\sqrt{n}} < \mu < \bar{x} + t_{n-1, \frac{\alpha}{2}} \frac{s}{\sqrt{n}}
$$
\  

Que também pode ser escrito como:

$$
\bar{x} \pm ME
$$
Onde $ME$ é:

$$
ME = t_{n-1,\alpha/2} \frac{S}{\sqrt{n}}
$$



Sendo $tn-1,α/2$ o valor crítico da distribuição $t$ com $n-1$ g.l. e uma área de $\frac{\alpha}{2}$ em cada calda:




Apurando-se:

```{r q2 2a, options}
# Definição do Nível de Confiança
confianca_95 <- 0.95
# Cálculo do Número de Observações
n <- nrow(dados)
# Cálculo da Média
x_hat <- mean(dados$idade)
# Cálculo do Desvio Padrão
sd <- sd(dados$idade)
# Cálculo do Erro Padrão da Média
ep <- sd / sqrt(n) 
# Determinação do Valor Crítico t para o Intervalo de Confiança
t_obs <- qt(1 - ((1 - confianca_95) / 2) , n - 1)
# Cálculo da Margem de Erro
me <- t_obs * ep
# Cálculo do Limite Inferior do Intervalo de Confiança
limite_inferior <- x_hat - me
# Cálculo do Limite Inferior do Intervalo de Confiança
limite_superior <- x_hat + me
# Retorno dos Limites do Intervalo de Confiança
list(n, x_hat, sd, ep, limite_inferior, limite_superior)
```

\  

##### **b) A mesma técnica utilizada no item anterior poderia ser usada para estimar a renda média populacional?**

```{r q2 2b, options}
# A mesma técnica pode ser utilizada para qualquer variável quantitativa contínua.
```

\  

##### **c) Podemos estimar e interpretar intervalos de confiança da mesma forma que na letra "a" para a variável casados? E para a variável aposentado?**

Não é possível interpretar da mesma forma, pois a variável que contém o valor (`est_civil`) é dicotomica, sendo que para este caso, estima-se a proporção de cada valor, se casado ou solteiro.
O mesmo racional se aplica para a variável `aponsentado`, que também é dicotomica.




```{r q2 2c, options}
n <- nrow(dados)
p <- mean(dados$est_civil)  # proporção de casados
ep <- sqrt(p * (1 - p) / n)
z <- qnorm(0.975)  # pontuação z para 95% CI
me <- z * ep
limite_inferior <- p - me
limite_superior <- p + me
c(limite_inferior, limite_superior)

```
\  

Na apuração acima, estima-se que a proporção de casado está entre 47% e 54%, com o nível de confiança de 95%.

\  

##### **d) Qual será a interpretação correta ao estimarmos um intervalo de 95% para a média dos casados?**
\  

Conforme indicado no item acima, a interpretação seria a proporção de casados na população, com 95% de confiança.


\  

##### **e) Calcule um intervalo de confiança de 90% para a média de tempo no emprego atual da população.**

```{r q2 2e, options}
# Definição do Nível de Confiança
confianca_90 <- 0.90

# Cálculo do Número de Observações
n <- nrow(dados)

# Cálculo da Média do Tempo no Emprego Atual
x_hat_emprego <- mean(dados$t_empr_atual)

# Cálculo do Desvio Padrão do Tempo no Emprego Atual
sd_emprego <- sd(dados$t_empr_atual)

# Cálculo do Erro Padrão da Média do Tempo no Emprego Atual
error_padrao_emprego <- sd_emprego / sqrt(n)

# Determinação do Valor Crítico t para o Intervalo de Confiança
t_obs_emprego <- qt(1 - ((1 - confianca_90) / 2), df = n - 1)

# Cálculo da Margem de Erro para o Tempo no Emprego Atual
margem_erro_emprego <- t_obs_emprego * error_padrao_emprego

# Cálculo do Limite Inferior do Intervalo de Confiança para o Tempo no Emprego Atual
limite_inferior_emprego <- x_hat_emprego - margem_erro_emprego

# Cálculo do Limite Superior do Intervalo de Confiança para o Tempo no Emprego Atual
limite_superior_emprego <- x_hat_emprego + margem_erro_emprego

# Retorno dos Limites do Intervalo de Confiança
c(limite_inferior_emprego, limite_superior_emprego)

```

\  

##### **f) Calcule um intervalo de confiança de 99% para a proporção de mulheres na população.**

```{r q2 2f, options}
# Cálculo da proporção de mulheres no dataframe
prop_mulheres <- mean(dados$sexo == "f")

# Cálculo do erro padrão para a proporção de mulheres
se_mulheres <- sqrt(prop_mulheres * (1 - prop_mulheres) / nrow(dados))

# Definição do nível de confiança
confianca_99 <- 0.99

# Determinação do valor crítico Z para o intervalo de confiança de 99%
z_score <- qnorm(1 - (1 - confianca_99) / 2)

# Cálculo da margem de erro usando Z-score
me_mulheres <- z_score * se_mulheres

# Cálculo dos limites do intervalo de confiança para a proporção de mulheres
c(prop_mulheres - me_mulheres, prop_mulheres + me_mulheres)

```

\  

#### Item 2

Calcule o valor-p e decida se rejeita ou não a hipótese nula para cada
afirmação abaixo.
Adote o nível de significância de 5%.

\  

##### **a) A média de idade populacional é de 40 anos.**

$H_O:\mu = 40$   
$H_a:\mu \neq 40$ (teste bilateral)

```{r q2 3a, options}
h_0_idade <- 40
t_teste_idade <- (mean(dados$idade) - h_0_idade) / (sd(dados$idade) / sqrt(nrow(dados)))
t_teste_idade
p_valor_idade <- 2 * pt(-abs(t_teste_idade), df = nrow(dados) - 1)
p_valor_idade
```

```{r q2 3a grafico, options}
n <- nrow(dados)
df <- n - 1

# Criar dados para o gráfico
x <- seq(-4, 4, length.out = 300)
df_t <- data.frame(x = x, y = dt(x, df))

# Adicionar regiões críticas
critical_left <- qt(0.025, df, lower.tail = TRUE)
critical_right <- qt(0.025, df, lower.tail = FALSE)

# Gráfico
p <- ggplot(df_t, aes(x = x, y = y)) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = t_teste_idade, color = "blue", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_left, color = "red", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_right, color = "red", linetype = "dashed", linewidth = 1) +
  geom_area(data = df_t %>% filter(x <= critical_left), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  geom_area(data = df_t %>% filter(x >= critical_right), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  labs(title = "Distribuição t e Estatística de Teste",
       subtitle = paste("Teste de hipótese para média de idade, p-valor:", round(p_valor_idade, 4)),
       x = "Valores t", y = "Densidade") +
  theme_minimal()

print(p)
```

\   

##### **b) A população sob amostragem vive, em média, 11 anos no mesmo endereço.**

$H_O:\mu = 11$  
$H_A: \mu \neq 11$

```{r q2 3b, options}
h_0_endereco <- 11
t_teste_endereco <- (mean(dados$endereco) - h_0_endereco) / (sd(dados$endereco) / sqrt(nrow(dados)))
p_valor_endereco <- 2 * pt(-abs(t_teste_endereco), df = nrow(dados) - 1)

t_teste_endereco
p_valor_endereco
```

```{r q2 3b grafico, options}
n <- nrow(dados)
df <- n - 1

# Criar dados para o gráfico
x <- seq(-4, 4, length.out = 300)
df_t <- data.frame(x = x, y = dt(x, df))

# Adicionar regiões críticas
critical_left <- qt(0.025, df, lower.tail = TRUE)
critical_right <- qt(0.025, df, lower.tail = FALSE)

# Gráfico
p <- ggplot(df_t, aes(x = x, y = y)) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = t_teste_endereco, color = "blue", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_left, color = "red", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_right, color = "red", linetype = "dashed", linewidth = 1) +
  geom_area(data = df_t %>% filter(x <= critical_left), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  geom_area(data = df_t %>% filter(x >= critical_right), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  labs(title = "Distribuição t e Estatística de Teste",
       subtitle = paste("Teste de hipótese para tempo de moradia, p-valor:", round(p_valor_endereco, 4)),
       x = "Valores t", y = "Densidade") +
  theme_minimal()

print(p)
```

\  

##### **c) Quais as chances de termos cometido um erro de decisão no item (a) e no item (b)?**

```{r q2 3c, options}
# O nível de significância é a chance de erro tipo I (rejeitar H0 quando é verdadeira).
alfa <- 0.05
alfa
```

\  

##### **d) A média de preço do carro principal das famílias nessa população está acima de R\$ 30.000,00.**

Se: 

$H_O:\mu = 30000$   
$H_a: \mu > 30000$ (teste unilateral à direita)

O teste t é:

$$
t = \frac{\bar{x}- \mu_0}{ \frac{s}{\sqrt{n}}} \text{, para } df = n-1\text{, } n < 30 \text{ e } \sigma \text{ desconhecido}
$$

\  

Apura-se:

```{r q2 3d, options}
h_0_carro <- 30
t_teste_carro <- (mean(dados$carro) - h_0_carro) / (sd(dados$carro) / sqrt(nrow(dados)))
p_valor_carro <- pt(t_teste_carro, df = nrow(dados) - 1)

mean(dados$carro)
sd(dados$carro)
t_teste_carro
p_valor_carro
```

Dado que o p-valor é maior que o nível de significância, aceita-se
$H_0$, sugerindo que a média de preço do carro principal é
 que R\$ 30.000,00.

```{r q2 3d grafico, options}
n <- nrow(dados)
df <- n - 1

# Criar dados para o gráfico
x <- seq(-4, 4, length.out = 300)
df_t <- data.frame(x = x, y = dt(x, df))

# Adicionar regiões críticas
critical_left <- qt(0.025, df, lower.tail = TRUE)
critical_right <- qt(0.025, df, lower.tail = FALSE)

# Gráfico
p <- ggplot(df_t, aes(x = x, y = y)) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = t_teste_carro, color = "blue", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_left, color = "red", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_right, color = "red", linetype = "dashed", linewidth = 1) +
  geom_area(data = df_t %>% filter(x <= critical_left), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  geom_area(data = df_t %>% filter(x >= critical_right), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  labs(title = "Distribuição t e Estatística de Teste",
       subtitle = paste("Teste de hipótese para média de idade, t observado:", round(t_teste_carro,4), "p-valor:", round(p_valor_carro, 4)),
       x = "Valores t", y = "Densidade") +
  theme_minimal()

print(p)
```

\  


##### **e) Em média, permanece-se menos de 11 anos no mesmo emprego.**

$H_O:\mu = 11$   
$H_a: \mu > 11$  (teste unilateral à direita)

```{r q2 3e, options}
h_0_emprego <- 11
t_teste_emprego <- (mean(dados$t_empr_atual) - h_0_emprego) / (sd(dados$t_empr_atual) / sqrt(nrow(dados)))
p_valor_emprego <- pt(-abs(t_teste_emprego), df = nrow(dados) - 1)

t_teste_emprego
p_valor_emprego
```

Não é possível rejeitar $H_0$

```{r q2 3e grafico, options}
n <- nrow(dados)
df <- n - 1

# Criar dados para o gráfico
x <- seq(-4, 4, length.out = 300)
df_t <- data.frame(x = x, y = dt(x, df))

# Adicionar regiões críticas
critical_left <- qt(0.025, df, lower.tail = TRUE)
critical_right <- qt(0.025, df, lower.tail = FALSE)

# Gráfico
p <- ggplot(df_t, aes(x = x, y = y)) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = t_teste_emprego, color = "blue", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_left, color = "red", linetype = "dashed", linewidth = 1) +
  geom_vline(xintercept = critical_right, color = "red", linetype = "dashed", linewidth = 1) +
  geom_area(data = df_t %>% filter(x <= critical_left), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  geom_area(data = df_t %>% filter(x >= critical_right), aes(x = x, y = y), fill = "red", alpha = 0.5) +
  labs(title = "Distribuição t e Estatística de Teste",
       subtitle = paste("Teste de hipótese para média de idade, p-valor:", round(p_valor_emprego, 4)),
       x = "Valores t", y = "Densidade") +
  theme_minimal()

print(p)
```

\  

##### **f) Metade da população é casada.**

Se:

$H_0: p_0 = 0.5$  
$H_a: p_0 \neq 0.5$ (bilateral)

Sendo que o teste T é calculado com:
$$
t = \frac{\hat{p} - p_0} {SE}
$$  

\  

Apura-se:
```{r q2 3f, options}
h_0_casados <- 0.5
prop_casados <- mean(dados$est_civil)  # Calcular a proporção de casados na amostra
n <- nrow(dados)  # Número de observações na amostra
se_casados <- sqrt(prop_casados * (1 - prop_casados) / n)  # Calcular o erro padrão da proporção
t_teste_casados <- (prop_casados - h_0_casados) / se_casados # Calcular a estatística T
p_valor_casados <- 2 * pt(-abs(t_teste_casados), df = n - 1) # Calcular o p-valor para um teste bilateral

prop_casados
se_casados
t_teste_casados
p_valor_casados
```

Não rejeita-se $H_0$
